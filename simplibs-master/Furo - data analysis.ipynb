{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drill - Data Analysis\n",
    "\n",
    "Analysis of the spectral data obtained for samples of the drill at Mina do Barroso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from core.experiment import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data table with samples and concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H</th>\n",
       "      <th>He</th>\n",
       "      <th>Li</th>\n",
       "      <th>Be</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>F</th>\n",
       "      <th>Ne</th>\n",
       "      <th>...</th>\n",
       "      <th>Rg</th>\n",
       "      <th>Cn</th>\n",
       "      <th>Nh</th>\n",
       "      <th>Fl</th>\n",
       "      <th>Mc</th>\n",
       "      <th>Lv</th>\n",
       "      <th>Ts</th>\n",
       "      <th>Og</th>\n",
       "      <th>Li2O</th>\n",
       "      <th>Chemistry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DRI0000001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI0000002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI0000003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI0000004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI0000005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI0000125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI0000126</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1860</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI0000127</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4280</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI0000128</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4970</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI0000129</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4370</td>\n",
       "      <td>177.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FGP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             H  He     Li     Be  B  C  N  O  F  Ne  ...  Rg  Cn  Nh  Fl  Mc  \\\n",
       "Sample ID                                            ...                       \n",
       " DRI0000001  0   0      0    0.0  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       " DRI0000002  0   0      0    0.0  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       " DRI0000003  0   0      0    0.0  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       " DRI0000004  0   0      0    0.0  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       " DRI0000005  0   0      0    0.0  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       "...         ..  ..    ...    ... .. .. .. .. ..  ..  ...  ..  ..  ..  ..  ..   \n",
       " DRI0000125  0   0  11000  108.0  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       " DRI0000126  0   0   1860  209.0  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       " DRI0000127  0   0   4280  160.0  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       " DRI0000128  0   0   4970  139.0  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       " DRI0000129  0   0   4370  177.5  0  0  0  0  0   0  ...   0   0   0   0   0   \n",
       "\n",
       "             Lv  Ts  Og  Li2O  Chemistry  \n",
       "Sample ID                                 \n",
       " DRI0000001   0   0   0     0        NaN  \n",
       " DRI0000002   0   0   0     0        NaN  \n",
       " DRI0000003   0   0   0     0        NaN  \n",
       " DRI0000004   0   0   0     0        NaN  \n",
       " DRI0000005   0   0   0     0        NaN  \n",
       "...          ..  ..  ..   ...        ...  \n",
       " DRI0000125   0   0   0     0        FGP  \n",
       " DRI0000126   0   0   0     0        FGP  \n",
       " DRI0000127   0   0   0     0        FGP  \n",
       " DRI0000128   0   0   0     0        FGP  \n",
       " DRI0000129   0   0   0     0        FGP  \n",
       "\n",
       "[129 rows x 89 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"D:\\\\Data_LIBS\\\\Furo\\\\Furo\\\\\"\n",
    "concentration_data = pd.read_csv(root_path+\"Furo.csv\",sep=\";\")\n",
    "concentration_data.set_index(\"Sample ID\", inplace=True)\n",
    "concentration_data2 = concentration_data['Chemistry'].groupby('Sample ID').first()\n",
    "concentration_data1 = concentration_data.groupby('Sample ID').mean()\n",
    "\n",
    "concentration_data3 = pd.concat([concentration_data1, concentration_data2], axis=1, join='outer', sort=True)\n",
    "concentration_data3.head(len(concentration_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concentration_data3.index\n",
    "concentration_data3.loc[' DRI0000001','Chemistry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading Folder DRI0000129 - 129 of 129\r"
     ]
    }
   ],
   "source": [
    "sample_index = 128\n",
    "\n",
    "#Use the following delay in Q switch\n",
    "delay = 370\n",
    "\n",
    "if delay == 340:\n",
    "    folders2 = [\"\\\\340spot1\\\\\",\"\\\\340spot2\\\\\",\"\\\\340spot3\\\\\",\"\\\\340spot4\\\\\"]\n",
    "    folders1 = [\"\\\\340 Spot 1\\\\\",\"\\\\340 Spot 2\\\\\",\"\\\\340 Spot 3\\\\\",\"\\\\340 Spot 4\\\\\"]\n",
    "\n",
    "elif delay == 370:  \n",
    "    folders2 = [\"\\\\370spot1\\\\\",\"\\\\370spot2\\\\\",\"\\\\370spot3\\\\\",\"\\\\370spot4\\\\\"]\n",
    "    folders1 = [\"\\\\370 Spot 1\\\\\",\"\\\\370 Spot 2\\\\\",\"\\\\370 Spot 3\\\\\",\"\\\\370 Spot 4\\\\\"]\n",
    "\n",
    "elif delay == 390:\n",
    "    folders = [\"\\\\390spot1\\\\\",\"\\\\390spot2\\\\\",\"\\\\390spot3\\\\\",\"\\\\390spot4\\\\\"]\n",
    "\n",
    "\n",
    "sample_folders = [f for f in os.listdir(root_path) if os.path.isdir(root_path + f)]\n",
    "#sample_folders = [sample_folders[sample_index]]\n",
    "folders=folders1\n",
    "\n",
    "\n",
    "list_of_experiments = []\n",
    "sample_ids = []\n",
    "for i in range(0,len(sample_folders)):\n",
    "    sample_f = sample_folders[i]\n",
    "    print(\" Reading Folder \"+ sample_f + \" - \"+ str(i+1) + \" of \" + str(len(sample_folders)), end=\"\\r\")\n",
    "\n",
    "    folder = folders[0]\n",
    "    sample_folder = root_path + sample_f + folder\n",
    "    try:\n",
    "        current_experiment = experiment(sample_folder,ignore='0000')\n",
    "    except:\n",
    "        folders = folders2\n",
    "        folder = folders2[0]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        current_experiment = experiment(sample_folder,ignore='0000')\n",
    "        \n",
    "    list_to_concatenate = []\n",
    "\n",
    "    for i in range(1,len(folders)):\n",
    "        folder = folders[i]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        list_to_concatenate.append(experiment(sample_folder,ignore='0000'))\n",
    "\n",
    "    current_experiment.concatenate(list_to_concatenate)\n",
    "    #obtain the mean signal for the 3 shots\n",
    "    sg = current_experiment.mean_signal\n",
    "    list_of_experiments.append(current_experiment)\n",
    "    sample_ids.append(sample_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MSC version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Now loading MSC versions\")\n",
    "list_of_experiments_MSC = []\n",
    "sample_ids_MSC = []\n",
    "folders=folders1\n",
    "\n",
    "for i in range(0,len(sample_folders)):\n",
    "    sample_f = sample_folders[i]\n",
    "    print(\" Reading Folder \"+ sample_f + \" - \"+ str(i+1) + \" of \" + str(len(sample_folders)), end=\"\\r\")\n",
    "\n",
    "    folder = folders[0]\n",
    "    sample_folder = root_path + sample_f + folder\n",
    "    try:\n",
    "        current_experiment = experiment(sample_folder,ignore='0000')\n",
    "        current_experiment.apply_msc_correction()\n",
    "        \n",
    "    except:\n",
    "        folders = folders2\n",
    "        folder = folders2[0]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        current_experiment = experiment(sample_folder,ignore='0000')\n",
    "        current_experiment.apply_msc_correction()\n",
    "        \n",
    "    list_to_concatenate = []\n",
    "\n",
    "    for i in range(1,len(folders)):\n",
    "        folder = folders[i]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        temp_exp = experiment(sample_folder,ignore='0000')\n",
    "        temp_exp.apply_msc_correction()\n",
    "        list_to_concatenate.append(experiment(sample_folder,ignore='0000'))\n",
    "\n",
    "    current_experiment.concatenate(list_to_concatenate)\n",
    "    #obtain the mean signal for the 3 shots\n",
    "    sg = current_experiment.mean_signal\n",
    "    list_of_experiments_MSC.append(current_experiment)\n",
    "    sample_ids_MSC.append(sample_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load normalized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Now loading normalized versions\")\n",
    "list_of_experiments_norm = []\n",
    "sample_ids_norm = []\n",
    "folders=folders1\n",
    "for i in range(0,len(sample_folders)):\n",
    "    sample_f = sample_folders[i]\n",
    "    print(\" Reading Folder \"+ sample_f + \" - \"+ str(i+1) + \" of \" + str(len(sample_folders)), end=\"\\r\")\n",
    "\n",
    "    folder = folders[0]\n",
    "    sample_folder = root_path + sample_f + folder\n",
    "    try:\n",
    "        current_experiment = experiment(sample_folder,ignore='0000',normalize=True)\n",
    "    except:\n",
    "        folders = folders2\n",
    "        folder = folders2[0]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        current_experiment = experiment(sample_folder,ignore='0000',normalize=True)\n",
    "        \n",
    "    list_to_concatenate = []\n",
    "\n",
    "    for i in range(1,len(folders)):\n",
    "        folder = folders[i]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        list_to_concatenate.append(experiment(sample_folder,ignore='0000',normalize=True))\n",
    "\n",
    "    current_experiment.concatenate(list_to_concatenate)\n",
    "    #obtain the mean signal for the 3 shots\n",
    "    sg = current_experiment.mean_signal\n",
    "    list_of_experiments_norm.append(current_experiment)\n",
    "    sample_ids_norm.append(sample_f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SNV version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now loading SNV versions - Full\n",
      " Reading Folder DRI0000129 - 129 of 129\n",
      "Now loading SNV versions - Piecewise\n",
      " Reading Folder DRI0000129 - 129 of 129\r"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Now loading SNV versions - Full\")\n",
    "list_of_experiments_SNV_full = []\n",
    "sample_ids_SNV_full = []\n",
    "folders=folders1\n",
    "for i in range(0,len(sample_folders)):\n",
    "    sample_f = sample_folders[i]\n",
    "    print(\" Reading Folder \"+ sample_f + \" - \"+ str(i+1) + \" of \" + str(len(sample_folders)), end=\"\\r\")\n",
    "\n",
    "    folder = folders[0]\n",
    "    sample_folder = root_path + sample_f + folder\n",
    "    try:\n",
    "        current_experiment = experiment(sample_folder,ignore='0000',SNV='Full')\n",
    "    except:\n",
    "        folders = folders2\n",
    "        folder = folders2[0]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        current_experiment = experiment(sample_folder,ignore='0000',SNV='Full')\n",
    "        \n",
    "    list_to_concatenate = []\n",
    "\n",
    "    for i in range(1,len(folders)):\n",
    "        folder = folders[i]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        list_to_concatenate.append(experiment(sample_folder,ignore='0000',SNV='Full'))\n",
    "\n",
    "    current_experiment.concatenate(list_to_concatenate)\n",
    "    #obtain the mean signal for the 3 shots\n",
    "    sg = current_experiment.mean_signal\n",
    "    list_of_experiments_SNV_full.append(current_experiment)\n",
    "    sample_ids_SNV_full.append(sample_f)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Now loading SNV versions - Piecewise\")\n",
    "list_of_experiments_SNV_piece = []\n",
    "sample_ids_SNV_piece = []\n",
    "folders=folders1\n",
    "\n",
    "for i in range(0,len(sample_folders)):\n",
    "    sample_f = sample_folders[i]\n",
    "    print(\" Reading Folder \"+ sample_f + \" - \"+ str(i+1) + \" of \" + str(len(sample_folders)), end=\"\\r\")\n",
    "\n",
    "    folder = folders[0]\n",
    "    sample_folder = root_path + sample_f + folder\n",
    "    try:\n",
    "        current_experiment = experiment(sample_folder,ignore='0000',SNV='Piecewise')\n",
    "    except:\n",
    "        folders = folders2\n",
    "        folder = folders2[0]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        current_experiment = experiment(sample_folder,ignore='0000',SNV='Piecewise')\n",
    "        \n",
    "    list_to_concatenate = []\n",
    "\n",
    "    for i in range(1,len(folders)):\n",
    "        folder = folders[i]\n",
    "        sample_folder = root_path + sample_f + folder\n",
    "        list_to_concatenate.append(experiment(sample_folder,ignore='0000',SNV='Piecewise'))\n",
    "\n",
    "    current_experiment.concatenate(list_to_concatenate)\n",
    "    #obtain the mean signal for the 3 shots\n",
    "    sg = current_experiment.mean_signal\n",
    "    list_of_experiments_SNV_piece.append(current_experiment)\n",
    "    sample_ids_SNV_piece.append(sample_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis of the mean signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81579588 0.11956779 0.0242455  0.01739987 0.00657092]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8330a594224cb6bcbcd794d5392de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan' 'nan' 'nan' 'nan' 'nan' ' SCH' ' SCH' ' SCH' ' SCH' ' SCH'\n",
      " ' SCH+FGP' ' SCH+FGP' ' FGP+VQZ' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' SCH+FGP' ' SCH+FGP'\n",
      " ' FGP' ' FGP' ' SCH+FGP' ' SCH' ' SCH' ' SCH' ' SCH' ' SCH' ' SCH' ' SCH'\n",
      " ' SCH' ' SCH' ' SCH+FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' SCH+FGP' ' SCH+FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:38: DeprecationWarning: scipy.array is deprecated and will be removed in SciPy 2.0.0, use numpy.array instead\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-66dddfb12163>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mlist_mean_signals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_mean_signals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_mean_signals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_mean_signals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mlist_mean_signals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_mean_signals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "pca_model = decomposition.PCA(n_components=5,)\n",
    "list_mean_signals = np.array([current_experiment.mean_signal.spectrum.flatten() for current_experiment in list_of_experiments])\n",
    "\n",
    "\n",
    "pca_model.fit(list_mean_signals)\n",
    "print(pca_model.explained_variance_ratio_)\n",
    "x = pca_model.transform(list_mean_signals)\n",
    "subplots()\n",
    "chemistry_labels=[]\n",
    "for i in range(0,len(sample_ids)):\n",
    "    chemistry_label = concentration_data3.loc[\" \"+str(sample_ids[i]),'Chemistry']\n",
    "    chemistry_labels.append(chemistry_label)\n",
    "\n",
    "chemistry_labels=np.array(chemistry_labels)\n",
    "print(chemistry_labels)\n",
    "index1 = where(chemistry_labels == ' SCH')[0]\n",
    "index2 = where(chemistry_labels == ' SCH+FGP')[0]\n",
    "index3 = where(chemistry_labels == ' FGP+VQZ')[0]\n",
    "index4 = where(chemistry_labels == ' FGP')[0]\n",
    "index5 = where(chemistry_labels == 'nan')[0]\n",
    "\n",
    "c1= 0\n",
    "c2= 1\n",
    "c3= 2\n",
    "plot(x[:,c1],x[:,c2],'o')\n",
    "\n",
    "plot(x[index1,c1],x[index1,c2],'o',color='b',label='SCH')\n",
    "plot(x[index2,c1],x[index2,c2],'o',color='r',label='SCH+FGP')\n",
    "plot(x[index3,c1],x[index3,c2],'o',color='k',label='FGP+VQZ')\n",
    "plot(x[index4,c1],x[index4,c2],'o',color='y',label='FGP')\n",
    "plot(x[index5,c1],x[index5,c2],'o',color='g',label='nan')\n",
    "xlabel(\"Principal Component 1\")\n",
    "ylabel(\"Principal Component 2\")\n",
    "legend()\n",
    "\n",
    "for i in range(0,10):\n",
    "    list_mean_signals = array(list_mean_signals)-np.mean(array(list_mean_signals),axis=0)\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(list_mean_signals)\n",
    "list_mean_signals = scaler.transform(list_mean_signals)\n",
    "\n",
    "pca_model.fit(list_mean_signals)\n",
    "print(pca_model.explained_variance_ratio_)\n",
    "x = pca_model.transform(list_mean_signals)\n",
    "subplots()\n",
    "chemistry_labels=[]\n",
    "for i in range(0,len(sample_ids)):\n",
    "    chemistry_label = concentration_data3.loc[\" \"+str(sample_ids[i]),'Chemistry']\n",
    "    chemistry_labels.append(chemistry_label)\n",
    "\n",
    "chemistry_labels=np.array(chemistry_labels)\n",
    "print(chemistry_labels)\n",
    "index1 = where(chemistry_labels == ' SCH')[0]\n",
    "index2 = where(chemistry_labels == ' SCH+FGP')[0]\n",
    "index3 = where(chemistry_labels == ' FGP+VQZ')[0]\n",
    "index4 = where(chemistry_labels == ' FGP')[0]\n",
    "index5 = where(chemistry_labels == 'nan')[0]\n",
    "\n",
    "c1= 0\n",
    "c2= 1\n",
    "c3= 2\n",
    "plot(x[:,c1],x[:,c2],'o')\n",
    "\n",
    "plot(x[index1,c1],x[index1,c2],'o',color='b',label='SCH')\n",
    "plot(x[index2,c1],x[index2,c2],'o',color='r',label='SCH+FGP')\n",
    "plot(x[index3,c1],x[index3,c2],'o',color='k',label='FGP+VQZ')\n",
    "plot(x[index4,c1],x[index4,c2],'o',color='y',label='FGP')\n",
    "plot(x[index5,c1],x[index5,c2],'o',color='g',label='nan')\n",
    "xlabel(\"Principal Component 1\")\n",
    "ylabel(\"Principal Component 2\")\n",
    "legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "ax.scatter(x[index1,c1], x[index1,c2], x[index1,c3], c='b',edgecolor='k')\n",
    "ax.scatter(x[index2,c1], x[index2,c2], x[index2,c3], c='r',edgecolor='k')\n",
    "ax.scatter(x[index3,c1], x[index3,c2], x[index3,c3], c='k',edgecolor='k')\n",
    "ax.scatter(x[index4,c1], x[index4,c2], x[index4,c3], c='y',edgecolor='k')\n",
    "plt.show()\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "df_pca = pd.DataFrame(x, columns=['PC1', 'PC2', 'PC3', 'PC4','PC5'])\n",
    "\n",
    "scatter_matrix(df_pca, alpha=0.2, figsize=(6, 6), diagonal='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293c28623c1546c1b5e737ca4cae36eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2048e53d5f8>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subplots()\n",
    "c1= 0\n",
    "c2= 1\n",
    "c3= 2\n",
    "ncomponents=5\n",
    "cs=np.arange(0,ncomponents,1)\n",
    "labs=['SCH','SCH+FGP','FGP+VQZ','FGP','nan']\n",
    "c=['b','r','k','y','g']\n",
    "indexes=np.array([index1,index2,index3,index4,index5])\n",
    "for a1 in range(0,ncomponents):\n",
    "    for a2 in range(0,ncomponents):\n",
    "        for i in range(0,len(labs)):\n",
    "            if a1!=a2:\n",
    "                subplot(ncomponents,ncomponents,(a1+1)+(a2)*ncomponents)\n",
    "                plot(x[indexes[i],cs[a1]],x[indexes[i],cs[a2]],'o',color=c[i],label=labs[i])\n",
    "legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLS regression for Lithium - mean signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fadb0bc408c4f68b4464be770efbb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5807884328847286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772b6214eaf44cba94cb067992668b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8158287364176982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PLSRegression(n_components=3, scale=False),\n",
       " 0.8158287364176982,\n",
       " 1756.6604672900462,\n",
       " 1827.5901435150065)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.tree import *\n",
    "\n",
    "ts = 0.1\n",
    "rs = 0\n",
    "ncomp = 3\n",
    "sigm=1.\n",
    "\n",
    "def SNV_transform(list_signals):\n",
    "    new_list=[]\n",
    "    for i in range(0,len(list_signals)):\n",
    "        new_list.append((list_signals[i]-np.mean(list_signals[i]))/sigm)\n",
    "    return new_list\n",
    "\n",
    "def normalize_transform(list_signals):\n",
    "    new_list=[]\n",
    "    for i in range(0,len(list_signals)):\n",
    "        new_list.append(list_signals[i]/np.sum(list_signals[i]))\n",
    "    return new_list\n",
    "    \n",
    "targets = []\n",
    "for i in range(0,len(sample_ids)):\n",
    "    target = concentration_data3.loc[\" \"+str(sample_ids[i]),'Li']\n",
    "    targets.append(target)\n",
    "targets = np.array(targets)\n",
    "\n",
    "def pls_concentration(list_of_experiments, targets,test_size=0.2,random_seed=0, ncomponents=5,\n",
    "                      Plot=True, Title='PLS Regression', label_x='Measured value', label_y='Predicted value', scaler = False):\n",
    "    \"\"\"\n",
    "    Returns a pls model and plot the result of a Partial Least squares regression\n",
    "    of the mean stiched spectrums for each experiment in the list_of_experiements \n",
    "    to a target concentration given in the targets array.\n",
    "    \n",
    "    \"\"\"\n",
    "    pls_model = cross_decomposition.PLSRegression(n_components = ncomponents, scale = scaler)\n",
    "    #pls_model = svm.SVR(kernel='poly', gamma='auto',coef0 = 1)\n",
    "    #pls_model = cross_decomposition.PLSRegression(n_components = ncomponents, scale = False)\n",
    "    #pls_model = neural_network.MLPRegressor()\n",
    "    #pls_model = ElasticNet()\n",
    "    #list_of_experiments=[current_experiment.mean_signal.remove_baseline() for current_experiment in list_of_experiments]\n",
    "    #print([current_experiment.mean_signal.density_H_alpha(Plot=False)[0] for current_experiment in list_of_experiments])\n",
    "    list_mean_signals = np.array([current_experiment.mean_signal.spectrum.flatten() for current_experiment in list_of_experiments])\n",
    "    #list_mean_signals = normalize_transform(list_mean_signals)\n",
    "    \n",
    "    \"\"\"\n",
    "    list_mean_signals = []\n",
    "    new_targets = []\n",
    "    for i in range(0,len(list_of_experiments)):\n",
    "        temp_list = []\n",
    "        for j in range(0,len(list_of_experiments[i].list_of_signals)):\n",
    "            list_mean_signals.append(np.array(list_of_experiments[i].list_of_signals[j].spectrum).flatten())\n",
    "            new_targets.append(targets[i])\n",
    "        \n",
    "    list_mean_signals = np.array(list_mean_signals)\n",
    "    print(list_mean_signals)\n",
    "    print(list_mean_signals.shape)\n",
    "    new_targets = np.array(new_targets)\n",
    "    print(new_targets.shape)\n",
    "    \n",
    "    if scaler:\n",
    "        #print(list_mean_signals)\n",
    "        scaler = StandardScaler()\n",
    "        #scaler = MinMaxScaler()\n",
    "        #scaler = Normalizer()\n",
    "        #scaler = RobustScaler()\n",
    "        scaler.fit(list_mean_signals)\n",
    "        list_mean_signals = scale(list_mean_signals,axis=1)\n",
    "        #list_mean_signals = scaler.transform(list_mean_signals)\n",
    "        #print(list_mean_signals)\n",
    "    \n",
    "    #subplots()\n",
    "    #plot(list_mean_signals[:,3],'o')\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(list_mean_signals, targets, \n",
    "                                                        test_size=test_size, random_state=random_seed)\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(list_mean_signals, new_targets, \n",
    "     #                                                   test_size=test_size, random_state=random_seed)\n",
    "    pls_model.fit(X_train,y_train)\n",
    "    r2=pls_model.score(X_test, y_test) \n",
    "    RMSE_p = mean_squared_error(y_test,pls_model.predict(X_test),squared = False)\n",
    "    RMSE_t = mean_squared_error(y_train,pls_model.predict(X_train),squared = False)\n",
    "    if Plot:\n",
    "        subplots()\n",
    "\n",
    "        ###With baseline\n",
    "        #subplot(121)\n",
    "        title(Title)\n",
    "\n",
    "        ax = gca()\n",
    "        ax.text(0.6, 0.1,  '$r^2 =$' + \"%0.4f\" % r2 + '\\n'\n",
    "                +'$RMSE_p =$' + \"%0.4f\" % RMSE_p + '\\n'\n",
    "                +'$RMSE_t =$' + \"%0.4f\" % RMSE_t ,\n",
    "                        transform=ax.transAxes,fontsize=8, bbox={'boxstyle':'round', 'facecolor': 'wheat', 'alpha': 0.5, 'pad': 0.5})\n",
    "\n",
    "        print(r2)\n",
    "        predicted = pls_model.predict(X_test)\n",
    "        predicted_train = pls_model.predict(X_train)\n",
    "        plot(y_test,predicted,'o',color = 'r', markersize=4,label = 'Test Dataset')\n",
    "        plot(y_train,predicted_train,'o',color = 'grey', markersize=2, label = 'Train Dataset')\n",
    "\n",
    "        mm=max([max(targets),max(predicted)])\n",
    "        xyline =np.linspace(0,mm,5) \n",
    "        plot(xyline,xyline,'-',color = 'grey', lw=0.5)\n",
    "        xlabel(label_x)\n",
    "        ylabel(label_y)\n",
    "        legend()\n",
    "    \n",
    "    return pls_model, r2, RMSE_p, RMSE_t\n",
    "\n",
    "init = 5\n",
    "end = 129\n",
    "\n",
    "pls_concentration(list_of_experiments[init:end], targets[init:end],test_size=ts,random_seed=rs, ncomponents=ncomp,\n",
    "                      Plot=True, Title='With Standardization - Mean Signal', \n",
    "                  label_x='Lithium Concentration - Measured Value', label_y='Lithium Concentration - Predicted Value',\n",
    "                 scaler=True)\n",
    "\n",
    "pls_concentration(list_of_experiments[init:end], targets[init:end],test_size=ts,random_seed=rs, ncomponents=ncomp,\n",
    "                      Plot=True, Title='Without Standardization - Mean Signal', \n",
    "                  label_x='Lithium Concentration - Measured Value', label_y='Lithium Concentration - Predicted Value',\n",
    "                 scaler=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd7972c6eaf4f2b8784a69445d171fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def pls_crossval_score(list_of_experiments, targets,test_size=0.2,random_seed=0, \n",
    "                    nsplits = 5, \n",
    "                    ncomponents_min = 1, ncomponents_max = 5,delta_ncomponents = 1, \n",
    "                      Plot=True, Title='PLS Regression', label_x='Measured value', label_y='Predicted value', scaler = False):\n",
    "    \"\"\"\n",
    "    Returns a pls model and plot the result of a Partial Least squares regression\n",
    "    of the mean stiched spectrums for each experiment in the list_of_experiements \n",
    "    to a target concentration given in the targets array.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    list_mean_signals = np.array([current_experiment.mean_signal.spectrum.flatten() for current_experiment in list_of_experiments])\n",
    "\n",
    "    crossval = []\n",
    "    #scorer = make_scorer(mean_squared_error,greater_is_better = False)\n",
    "    \n",
    "    for n_components in range(ncomponents_min,ncomponents_max+1,delta_ncomponents):\n",
    "        pls_model = cross_decomposition.PLSRegression(n_components = n_components, scale = scaler)\n",
    "    \n",
    "        cv = ShuffleSplit(n_splits=nsplits, test_size=ts, random_state=rs)\n",
    "        scores = cross_val_score(pls_model, list_mean_signals, targets, cv=cv)\n",
    "        #scores = cross_val_score(pls_model, list_mean_signals, targets, cv=cv,scoring=scorer)\n",
    "        crossval.append(np.mean(scores))\n",
    "        \n",
    "    return range(ncomponents_min,ncomponents_max+1,delta_ncomponents), crossval\n",
    "\n",
    "rs=10\n",
    "init= 5 \n",
    "end = 39\n",
    "ncomps_x , scores_nonscaled = pls_crossval_score(list_of_experiments[init:end], targets[init:end],test_size=ts,random_seed=rs, nsplits = 5, \n",
    "                ncomponents_min = 2, ncomponents_max = 10,\n",
    "                      Plot=True, Title='Without Normalization - Mean Signal', \n",
    "                  label_x='Lithium Concentration - Measured Value', label_y='Lithium Concentration - Predicted Value',\n",
    "                 scaler=False)\n",
    "\n",
    "ncomps_x , scores_scaled = pls_crossval_score(list_of_experiments[init:end], targets[init:end],test_size=ts,random_seed=rs, nsplits = 5, \n",
    "                ncomponents_min = 2, ncomponents_max = 10,\n",
    "                      Plot=True, Title='Without Normalization - Mean Signal', \n",
    "                  label_x='Lithium Concentration - Measured Value', label_y='Lithium Concentration - Predicted Value',\n",
    "                 scaler=True)\n",
    "\n",
    "subplots()\n",
    "title('PLS Regression scores vs # of components')\n",
    "plot(ncomps_x, scores_nonscaled,'o',ls='-', lw=0.5, color='k', label = 'Non Scaled')\n",
    "plot(ncomps_x, scores_scaled,':',marker='*', lw=0.5, color='b',label = 'Scaled')\n",
    "legend()\n",
    "xlabel('# components')\n",
    "ylabel('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrome = 3\n",
    "exper = 10\n",
    "spectra10 = np.array([x.spectrum[spectrome] for x in list_of_experiments[exper].list_of_signals])\n",
    "wavel = list_of_experiments[exper].list_of_signals[0].wavelengths[spectrome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "def msc(input_data):\n",
    "    \"\"\"\n",
    "        :msc: Scatter Correction technique performed with mean of the sample data as the reference.\n",
    "        :param input_data: Array of spectral data\n",
    "        :type input_data: DataFrame\n",
    "        :returns: data_msc (ndarray): Scatter corrected spectra data\n",
    "    \"\"\"\n",
    "    \n",
    "    ref = []\n",
    "\n",
    "    # mean centre correction\n",
    "    for i in range(input_data.shape[0]):\n",
    "        input_data[i,:] -= input_data[i,:].mean()\n",
    "    \n",
    "    # Get the reference spectrum. If not given, estimate it from the mean\n",
    "    # Define a new array and populate it with the corrected data    \n",
    "    data_msc = np.zeros_like(input_data)\n",
    "    data_msc0 = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    "            ref.append(np.mean(input_data, axis=0))\n",
    "            # Run regression\n",
    "            fit = np.polyfit(ref[i], input_data[i,:], 1, full=True)\n",
    "            model = HuberRegressor()\n",
    "            model.fit(ref[i].reshape(-1,1),input_data[i,:])\n",
    "            #print(model.coef_)\n",
    "            #print(model.intercept_)\n",
    "            #print(fit)\n",
    "            # Apply correction\n",
    "            data_msc0[i,:] = (input_data[i,:] - fit[0][1]) / fit[0][0]\n",
    "            #Apply correction\n",
    "            data_msc[i,:] = (input_data[i,:] - model.intercept_) / model.coef_\n",
    "    \n",
    "    return (data_msc,data_msc0)\n",
    "\n",
    "#msc(spectra10)\n",
    "subplots()\n",
    "subplot(311)\n",
    "plot(wavel,transpose(spectra10))\n",
    "subplot(312)\n",
    "plot(wavel,transpose(msc(spectra10)[0]))\n",
    "subplot(313)\n",
    "plot(wavel,transpose(msc(spectra10)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNV_transform(list_signals):\n",
    "    new_list=[]\n",
    "    for i in range(0,len(list_signals)):\n",
    "        new_list.append((list_signals[i]-np.mean(list_signals[i]))/sigm)\n",
    "    return new_list\n",
    "\n",
    "def normalize_transform(list_signals):\n",
    "    new_list=[]\n",
    "    for i in range(0,len(list_signals)):\n",
    "        new_list.append(list_signals[i]/np.sum(list_signals[i]))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLS with Standard Normal Variate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pls_concentration(list_of_experiments, targets,test_size=ts,random_seed=rs, ncomponents=ncomp,\n",
    "                      Plot=True, Title='Without Normalization - Mean Signal', \n",
    "                  label_x='Lithium Concentration - Measured Value', label_y='Lithium Concentration - Predicted Value')\n",
    "\n",
    "\n",
    "###SNV transform\n",
    "subplot(121)\n",
    "title(\"With SNV - Piecewise\")\n",
    "\n",
    "\n",
    "\n",
    "list_SNV_piece = np.array([current_experiment.mean_signal.spectrum.flatten() \n",
    "                           for current_experiment in list_of_experiments_SNV_piece])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_SNV_piece, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "pls_model.fit(X_train,y_train)\n",
    "\n",
    "r2=pls_model.score(X_test, y_test) \n",
    "ax = gca()\n",
    "ax.text(0.6, 0.1,  '$r^2 =$' + \"%0.4f\" % r2,\n",
    "                transform=ax.transAxes,fontsize=8, bbox={'boxstyle':'round', 'facecolor': 'wheat', 'alpha': 0.5, 'pad': 0.5})\n",
    "\n",
    "print(r2)\n",
    "predicted = pls_model.predict(X_test)\n",
    "predicted_train = pls_model.predict(X_train)\n",
    "plot(y_test,predicted,'o',color = 'r', markersize=4,label = 'Test Dataset')\n",
    "plot(y_train,predicted_train,'o',color = 'grey', markersize=2, label = 'Train Dataset')\n",
    "\n",
    "#####\n",
    "mm=max([max(targets),max(predicted)])\n",
    "xyline =np.linspace(0,mm,5) \n",
    "plot(xyline,xyline,'-',color = 'grey', lw=0.5)\n",
    "xlabel(\"Lithium Concentration - Measured Value\")\n",
    "legend()\n",
    "\n",
    "\n",
    "###SNV transform\n",
    "subplot(122)\n",
    "title(\"With SNV - Full\")\n",
    "\n",
    "\n",
    "list_SNV_full = np.array([current_experiment.mean_signal.spectrum.flatten() \n",
    "                          for current_experiment in list_of_experiments_SNV_full])\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_SNV_full, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "pls_model.fit(X_train,y_train)\n",
    "\n",
    "r2=pls_model.score(X_test, y_test) \n",
    "ax = gca()\n",
    "ax.text(0.6, 0.1,  '$r^2 =$' + \"%0.4f\" % r2,\n",
    "                transform=ax.transAxes,fontsize=8, bbox={'boxstyle':'round', 'facecolor': 'wheat', 'alpha': 0.5, 'pad': 0.5})\n",
    "\n",
    "print(r2)\n",
    "predicted = pls_model.predict(X_test)\n",
    "predicted_train = pls_model.predict(X_train)\n",
    "plot(y_test,predicted,'o',color = 'r', markersize=4,label = 'Test Dataset')\n",
    "plot(y_train,predicted_train,'o',color = 'grey', markersize=2, label = 'Train Dataset')\n",
    "\n",
    "\n",
    "#####\n",
    "mm=max([max(targets),max(predicted)])\n",
    "xyline =np.linspace(0,mm,5) \n",
    "plot(xyline,xyline,'-',color = 'grey', lw=0.5)\n",
    "xlabel(\"Lithium Concentration - Measured Value\")\n",
    "legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLS MSC correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "subplots(figsize=[6,5])\n",
    "\n",
    "###SNV transform\n",
    "title(\"With MSC\")\n",
    "\n",
    "\n",
    "\n",
    "list_MSC = np.array([current_experiment.mean_signal.spectrum.flatten()\n",
    "                           for current_experiment in list_of_experiments_MSC])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_MSC, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "pls_model.fit(X_train,y_train)\n",
    "\n",
    "r2=pls_model.score(X_test, y_test) \n",
    "ax = gca()\n",
    "ax.text(0.6, 0.1,  '$r^2 =$' + \"%0.4f\" % r2,\n",
    "                transform=ax.transAxes,fontsize=8, bbox={'boxstyle':'round', 'facecolor': 'wheat', 'alpha': 0.5, 'pad': 0.5})\n",
    "\n",
    "print(r2)\n",
    "predicted = pls_model.predict(X_test)\n",
    "predicted_train = pls_model.predict(X_train)\n",
    "plot(y_test,predicted,'o',color = 'r', markersize=4,label = 'Test Dataset')\n",
    "plot(y_train,predicted_train,'o',color = 'grey', markersize=2, label = 'Train Dataset')\n",
    "\n",
    "#####\n",
    "mm=max([max(targets),max(predicted)])\n",
    "xyline =np.linspace(0,mm,5) \n",
    "plot(xyline,xyline,'-',color = 'grey', lw=0.5)\n",
    "xlabel(\"Lithium Concentration - Measured Value\")\n",
    "legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLS normalized to the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Normalized to total spectrum\n",
    "\n",
    "subplots()\n",
    "subplot(121)\n",
    "suptitle(\"Normalized to total spectrum\")\n",
    "title(\"Mean signal only\")\n",
    "\n",
    "list_mean_signals_norm = np.array([current_experiment.mean_signal.spectrum.flatten() \n",
    "                                   for current_experiment in list_of_experiments])\n",
    "\n",
    "\n",
    "list_normalized_mean = normalize_transform(list_mean_signals_norm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_normalized_mean, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "pls_model.fit(X_train,y_train)\n",
    "\n",
    "r2=pls_model.score(X_test, y_test) \n",
    "ax = gca()\n",
    "ax.text(0.6, 0.1,  '$r^2 =$' + \"%0.4f\" % r2,\n",
    "                transform=ax.transAxes,fontsize=8, bbox={'boxstyle':'round', 'facecolor': 'wheat', 'alpha': 0.5, 'pad': 0.5})\n",
    "\n",
    "print(r2)\n",
    "predicted = pls_model.predict(X_test)\n",
    "predicted_train = pls_model.predict(X_train)\n",
    "plot(y_test,predicted,'o',color = 'r', markersize=4,label = 'Test Dataset')\n",
    "plot(y_train,predicted_train,'o',color = 'grey', markersize=2, label = 'Train Dataset')\n",
    "\n",
    "\n",
    "#####\n",
    "mm=max([max(targets),max(predicted)])\n",
    "xyline =np.linspace(0,mm,5) \n",
    "plot(xyline,xyline,'-',color = 'grey', lw=0.5)\n",
    "xlabel(\"Lithium Concentration - Measured Value\")\n",
    "legend()\n",
    "\n",
    "###Normalized to total spectrum\n",
    "\n",
    "subplot(122)\n",
    "title(\"Each shot\")\n",
    "\n",
    "list_mean_signals_norm = np.array([current_experiment_norm.mean_signal.spectrum.flatten() \n",
    "                                   for current_experiment_norm in list_of_experiments_norm])\n",
    "\n",
    "list_normalized_each = list_mean_signals_norm\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_normalized_each, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "pls_model.fit(X_train,y_train)\n",
    "\n",
    "r2=pls_model.score(X_test, y_test) \n",
    "ax = gca()\n",
    "ax.text(0.6, 0.1,  '$r^2 =$' + \"%0.4f\" % r2,\n",
    "                transform=ax.transAxes,fontsize=8, bbox={'boxstyle':'round', 'facecolor': 'wheat', 'alpha': 0.5, 'pad': 0.5})\n",
    "\n",
    "print(r2)\n",
    "predicted = pls_model.predict(X_test)\n",
    "predicted_train = pls_model.predict(X_train)\n",
    "plot(y_test,predicted,'o',color = 'r', markersize=4,label = 'Test Dataset')\n",
    "plot(y_train,predicted_train,'o',color = 'grey', markersize=2, label = 'Train Dataset')\n",
    "\n",
    "#####\n",
    "mm=max([max(targets),max(predicted)])\n",
    "xyline =np.linspace(0,mm,5) \n",
    "plot(xyline,xyline,'-',color = 'grey', lw=0.5)\n",
    "xlabel(\"Lithium Concentration - Measured Value\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots()\n",
    "subplot(211)\n",
    "\n",
    "plot(list_normalized_each[5],label=\"Normalized\")\n",
    "plot(list_normalized_mean[5],label=\"Normalized\")\n",
    "#legend()\n",
    "subplot(212)\n",
    "plot(list_of_experiments_SNV_piece[0].list_of_signals[0].spectrum[4],label=\"SNV Piece\")\n",
    "plot(list_of_experiments_SNV_full[0].list_of_signals[0].spectrum[4],label=\"SNV Full\")\n",
    "legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "r2_mean_test=[]\n",
    "r2_mean_train=[]\n",
    "crossval_mean = []\n",
    "\n",
    "r2_snv_piece_test=[]\n",
    "r2_snv_piece_train=[]\n",
    "crossval_snv_piece = []\n",
    "\n",
    "r2_snv_full_test=[]\n",
    "r2_snv_full_train=[]\n",
    "crossval_snv_full = []\n",
    "\n",
    "r2_norm_each_test=[]\n",
    "r2_norm_each_train=[]\n",
    "crossval_norm_each = []\n",
    "\n",
    "r2_norm_mean_test=[]\n",
    "r2_norm_mean_train=[]\n",
    "crossval_norm_mean = []\n",
    "\n",
    "r2_MSC_test=[]\n",
    "r2_MSC_train=[]\n",
    "crossval_MSC = []\n",
    "\n",
    "rs=2\n",
    "max_nc= 15\n",
    "for ncomp in range(2,max_nc,1):\n",
    "    print(ncomp, end='\\r')\n",
    "    \n",
    "    pls_model = cross_decomposition.PLSRegression(n_components = ncomp)\n",
    "    list_mean_signals = np.array([current_experiment.mean_signal.spectrum.flatten() for current_experiment in list_of_experiments])\n",
    "\n",
    "    targets = []\n",
    "    for i in range(0,len(sample_ids)):\n",
    "        target = concentration_data3.loc[\" \"+str(sample_ids[i]),'Li']\n",
    "        targets.append(target)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(list_mean_signals, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "    pls_model.fit(X_train,y_train)\n",
    "\n",
    "    r2=pls_model.score(X_test, y_test)\n",
    "    r2t=pls_model.score(X_train, y_train)\n",
    "    r2_mean_test.append(r2)\n",
    "    r2_mean_train.append(r2t)\n",
    "    predicted = pls_model.predict(X_test)\n",
    "    predicted_train = pls_model.predict(X_train)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    scores = cross_val_score(pls_model, list_mean_signals, targets, cv=cv)\n",
    "    crossval_mean.append(np.mean(scores))\n",
    "    \n",
    "    try:\n",
    "        #####################SNV transform - FULL#######################################################\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(list_SNV_full, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "        pls_model.fit(X_train,y_train)\n",
    "\n",
    "        r2=pls_model.score(X_test, y_test)\n",
    "        r2t=pls_model.score(X_train, y_train)\n",
    "        r2_snv_full_test.append(r2)\n",
    "        r2_snv_full_train.append(r2t)\n",
    "\n",
    "        cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "        scores = cross_val_score(pls_model, list_SNV_full, targets, cv=cv)\n",
    "        crossval_snv_full.append(np.mean(scores))\n",
    "\n",
    "\n",
    "\n",
    "        #####################SNV transform - PIECE #######################################################\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(list_SNV_piece, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "        pls_model.fit(X_train,y_train)\n",
    "\n",
    "        r2=pls_model.score(X_test, y_test)\n",
    "        r2t=pls_model.score(X_train, y_train)\n",
    "        r2_snv_piece_test.append(r2)\n",
    "        r2_snv_piece_train.append(r2t)\n",
    "\n",
    "        scores = cross_val_score(pls_model, list_SNV_piece, targets, cv=cv)\n",
    "        crossval_snv_piece.append(np.mean(scores))\n",
    "    except:\n",
    "        print('SNV not loaded')\n",
    "        \n",
    "    try:\n",
    "        #####################Mean - All #######################################################\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(list_normalized_mean, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "        pls_model.fit(X_train,y_train)\n",
    "\n",
    "        r2=pls_model.score(X_test, y_test)\n",
    "        r2t=pls_model.score(X_train, y_train)\n",
    "        r2_norm_mean_test.append(r2)\n",
    "        r2_norm_mean_train.append(r2t)\n",
    "\n",
    "        scores = cross_val_score(pls_model, list_normalized_mean, targets, cv=cv)\n",
    "        crossval_norm_mean.append(np.mean(scores))\n",
    "    \n",
    "        ##################### Mean - Each #######################################################\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(list_normalized_each, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "        pls_model.fit(X_train,y_train)\n",
    "\n",
    "        r2=pls_model.score(X_test, y_test)\n",
    "        r2t=pls_model.score(X_train, y_train)\n",
    "        r2_norm_each_test.append(r2)\n",
    "        r2_norm_each_train.append(r2t)\n",
    "\n",
    "        scores = cross_val_score(pls_model, list_normalized_each, targets, cv=cv)\n",
    "        crossval_norm_each.append(np.mean(scores))\n",
    "    except:\n",
    "        print('Normalized data not loaded')\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        ##################### MSC #######################################################\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(list_MSC, targets, test_size=ts, random_state=rs)\n",
    "\n",
    "        pls_model.fit(X_train,y_train)\n",
    "\n",
    "        r2=pls_model.score(X_test, y_test)\n",
    "        r2t=pls_model.score(X_train, y_train)\n",
    "        r2_MSC_test.append(r2)\n",
    "        r2_MSC_train.append(r2t)\n",
    "\n",
    "        scores = cross_val_score(pls_model, list_MSC, targets, cv=cv)\n",
    "        crossval_MSC.append(np.mean(scores))\n",
    "    except:\n",
    "        print('MSC not loaded')\n",
    "        \n",
    "print(\"Crossvalidation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots()\n",
    "ncompon=np.arange(2,max_nc,1)\n",
    "title(\"Comparison of Scores for PLS\")\n",
    "plot(ncompon,crossval_mean,'o',color='r',ls='--',label='No normalization')\n",
    "try:\n",
    "    plot(ncompon,crossval_snv_piece,'s',color='gray',ls='-.',label='SNV - Piecewise')\n",
    "    plot(ncompon,crossval_snv_full,'*',color='k',ls='-',label='SNV - Full')\n",
    "    plot(ncompon,crossval_norm_each,'.',color='b',ls='--',label='Normalized - Each')\n",
    "    plot(ncompon,crossval_norm_mean,'o',color='g',ls='-.',label='Normalized - Mean')\n",
    "except:\n",
    "    None\n",
    "plot(ncompon,crossval_MSC,'o',color='g',ls='-.',label='MSC correction')\n",
    "xlabel(\"Number of Components\")\n",
    "ylabel(r\"$R^2$\")\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots(figsize=[20,4])\n",
    "suptitle(\"PLS score, 5-fold crossvalidation\")\n",
    "subplot(151)\n",
    "ncompon=np.arange(2,max_nc,1)\n",
    "title(\"Without normalization\")\n",
    "plot(ncompon,r2_mean_test,'o',color='r',ls='--')\n",
    "plot(ncompon,r2_mean_train,'o',color='gray',ls=':')\n",
    "plot(ncompon,np.ones(ncompon.shape)*0.8,color='gray',ls='--',lw=0.5)\n",
    "xlabel(\"Number of Components\")\n",
    "ylim([0.5,1.1])\n",
    "xlim([min(ncompon),max(ncompon)])\n",
    "subplot(152)\n",
    "title(\"With SNV - Piecewise\")\n",
    "plot(ncompon,r2_snv_piece_test,'o',color='r',ls='--')\n",
    "plot(ncompon,r2_snv_piece_train,'o',color='gray',ls=':')\n",
    "plot(ncompon,np.ones(ncompon.shape)*0.8,color='gray',ls='--',lw=0.5)\n",
    "xlabel(\"Number of Components\")\n",
    "ylim([0.5,1.1])\n",
    "xlim([min(ncompon),max(ncompon)])\n",
    "subplot(153)\n",
    "title(\"With SNV - Full\")\n",
    "plot(ncompon,r2_snv_full_test,'o',color='r',ls='--')\n",
    "plot(ncompon,r2_snv_full_train,'o',color='gray',ls=':')\n",
    "plot(ncompon,np.ones(ncompon.shape)*0.8,color='gray',ls='--',lw=0.5)\n",
    "xlabel(\"Number of Components\")\n",
    "ylim([0.5,1.1])\n",
    "xlim([min(ncompon),max(ncompon)])\n",
    "subplot(154)\n",
    "title(\"Normalized - Each Shot\")\n",
    "plot(ncompon,r2_norm_each_test,'o',color='r',ls='--')\n",
    "plot(ncompon,r2_norm_each_train,'o',color='gray',ls=':')\n",
    "plot(ncompon,np.ones(ncompon.shape)*0.8,color='gray',ls='--',lw=0.5)\n",
    "xlabel(\"Number of Components\")\n",
    "ylim([0.5,1.1])\n",
    "xlim([min(ncompon),max(ncompon)])\n",
    "subplot(155)\n",
    "title(\"Normalized - Mean of Shots\")\n",
    "plot(ncompon,r2_norm_mean_test,'o',color='r',ls='--')\n",
    "plot(ncompon,r2_norm_mean_train,'o',color='gray',ls=':')\n",
    "plot(ncompon,np.ones(ncompon.shape)*0.8,color='gray',ls='--',lw=0.5)\n",
    "xlabel(\"Number of Components\")\n",
    "ylim([0.5,1.1])\n",
    "xlim([min(ncompon),max(ncompon)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=3)\n",
    "scores = cross_val_score(pls_model, list_normalized_each, targets, cv=cv)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Lithium lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ded87b65cf047e782e311bf9dbb1ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Warning, asked for 5 only got 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57911062b7e452fab3f87605e941595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7041b2fa07fa4987b2a094261dcb06fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x185aa9e0160>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al = element('Li')\n",
    "\n",
    "Tp = 1.*T_ref\n",
    "sg = current_experiment.mean_signal\n",
    "\n",
    "n_spectrometer = 7\n",
    "ll = sg.wavelengths[n_spectrometer][0]\n",
    "ul = sg.wavelengths[n_spectrometer][-1]\n",
    "\n",
    "ion_energies = al.ion_energies\n",
    "\n",
    "#ion state 1\n",
    "nlines = 5\n",
    "l_num, lines = al.get_most_relevant_lines_ion_state(ion_state = 1, electron_temperature=Tp, n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "j=1\n",
    "current_experiment = list_of_experiments[j]\n",
    "#print(current_experiment.list_of_signals)\n",
    "#print(sample_ids[j])\n",
    "#stich the wavelengths and spectrum (not the best way, but for now let us have it)\n",
    "wavelengths = np.concatenate([w for w in current_experiment.mean_signal.wavelengths]) \n",
    "spectrum = np.concatenate([s for s in current_experiment.mean_signal.spectrum ])\n",
    "\n",
    "#get peak area\n",
    "ritz = lines[0].ritz\n",
    "subplots()\n",
    "intensity = get_peak_area(ritz,0.5 , wavelengths, spectrum, 0.3, True)\n",
    "\n",
    "line_0=lines[0]\n",
    "\n",
    "n_spectrometer = 5\n",
    "ll = sg.wavelengths[n_spectrometer][0]\n",
    "ul = sg.wavelengths[n_spectrometer][-1]\n",
    "\n",
    "ion_energies = al.ion_energies\n",
    "\n",
    "#ion state 1\n",
    "nlines = 5\n",
    "l_num, lines = al.get_most_relevant_lines_ion_state(ion_state = 1, electron_temperature=Tp, n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "j=0\n",
    "current_experiment = list_of_experiments[j]\n",
    "#print(current_experiment.list_of_signals)\n",
    "#print(sample_ids[j])\n",
    "#stich the wavelengths and spectrum (not the best way, but for now let us have it)\n",
    "wavelengths = np.concatenate([w for w in current_experiment.mean_signal.wavelengths]) \n",
    "spectrum = np.concatenate([s for s in current_experiment.mean_signal.spectrum ])\n",
    "\n",
    "#get peak area\n",
    "ritz = lines[0].ritz\n",
    "subplots()\n",
    "intensity = get_peak_area(ritz,0.5 , wavelengths, spectrum, 0.3, True)\n",
    "\n",
    "line_1=lines[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "subplots()\n",
    "plot(wavelengths,spectrum, '-', lw=0.5, color='k')\n",
    "j=124\n",
    "current_experiment = list_of_experiments[j]\n",
    "#stich the wavelengths and spectrum (not the best way, but for now let us have it)\n",
    "wavelengths = np.concatenate([w for w in current_experiment.mean_signal.wavelengths]) \n",
    "spectrum = np.concatenate([s for s in current_experiment.mean_signal.spectrum ])\n",
    "plot(wavelengths,spectrum, '-', lw=0.5, color='r')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83be3a547804b629fbfcf830cd267cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7998e632c20478487c65b4c538a9841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\_lib\\deprecation.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return fun(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sample = digital_twin([['Li',1]])\n",
    "n_spectrometer = 5\n",
    "\n",
    "ll = sg.wavelengths[n_spectrometer][0]\n",
    "ul = sg.wavelengths[n_spectrometer][-1]\n",
    "\n",
    "#ion state 1\n",
    "nlines = 3\n",
    "l_num, lines = al.get_most_relevant_lines_ion_state(ion_state = 1, electron_temperature=Tp, \n",
    "                                                        n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "#line to normalize the intensity for direct\n",
    "line_norm1=lines[1]\n",
    "sg.compare_and_peaks(sample, spectrometer=n_spectrometer,max_ion_state=2, \n",
    "                                 electron_temperature = Tp,\n",
    "                                 d_lambda=0.02, use_wavelengths=True,line_normalize=line_norm1,Plotline = True, resolution = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Calibration - Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line of Wavelength 610.364\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: scipy.array is deprecated and will be removed in SciPy 2.0.0, use numpy.array instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84aaf07da7db45559ffec7e2bd25a76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2083236446722857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def linear_calibration_curve(list_of_experiments, targets, line, ratio_of_maximum = 0.5, radius = 0.3, \n",
    "                    test_size=ts,random_seed=rs,\n",
    "                    Plot=True, Title='Linear Calibration Curve', \n",
    "                  label_x='Measured Value', label_y='Predicted Value'):\n",
    "\n",
    "    intensities=[]\n",
    "\n",
    "    for j in range(0,len(list_of_experiments)):\n",
    "        current_experiment = list_of_experiments[j]\n",
    "        \n",
    "        #stich the wavelengths and spectrum (not the best way, but for now let us have it)\n",
    "        wavelengths = np.concatenate([w for w in current_experiment.mean_signal.wavelengths]) \n",
    "        spectrum = np.concatenate([s for s in current_experiment.mean_signal.spectrum ])\n",
    "        spectrum = spectrum/(np.sum(spectrum))\n",
    "        #get peak area\n",
    "        ritz = line.ritz\n",
    "        intensity = get_peak_area(ritz,ratio_of_maximum , wavelengths, spectrum, radius, False)\n",
    "        intensities.append(intensity)\n",
    "    \n",
    "    intensities=array(intensities)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(intensities.reshape(-1, 1), targets.reshape(-1, 1), \n",
    "                                                        test_size=test_size, random_state=random_seed)\n",
    "    \n",
    "    UCC_model = linear_model.LinearRegression()\n",
    "    UCC_model.fit(X_train,y_train)\n",
    "    r2=UCC_model.score(X_test, y_test) \n",
    "    \n",
    "    if Plot:\n",
    "        subplots()\n",
    "\n",
    "        ###With baseline\n",
    "        #subplot(121)\n",
    "        title(\"Without Normalization - Mean Signal\")\n",
    "\n",
    "        ax = gca()\n",
    "        ax.text(0.6, 0.1,  '$r^2 =$' + \"%0.4f\" % r2,\n",
    "                        transform=ax.transAxes,fontsize=8, bbox={'boxstyle':'round', 'facecolor': 'wheat', 'alpha': 0.5, 'pad': 0.5})\n",
    "\n",
    "        print(r2)\n",
    "        predicted = UCC_model.predict(X_test)\n",
    "        predicted_train = UCC_model.predict(X_train)\n",
    "        plot(y_test,predicted,'o',color = 'r', markersize=4,label = 'Test Dataset')\n",
    "        plot(y_train,predicted_train,'o',color = 'grey', markersize=2, label = 'Train Dataset')\n",
    "\n",
    "        mm=max([max(targets),max(predicted)])\n",
    "        xyline =np.linspace(0,mm,5) \n",
    "        plot(xyline,xyline,'-',color = 'grey', lw=0.5)\n",
    "        xlabel(label_x)\n",
    "        ylabel(label_y)\n",
    "        legend()\n",
    "        \n",
    "    \n",
    "    return UCC_model, r2, intensities, targets\n",
    "\n",
    "\n",
    "line = lines[0]\n",
    "print(line)\n",
    "init = 0#5\n",
    "end = 129#39\n",
    "UCC_model, r2, intensities, targets0 = linear_calibration_curve(list_of_experiments[init:end], targets[init:end], line, ratio_of_maximum = 0.5, radius = 0.3, \n",
    "                    test_size=ts,random_seed=rs,\n",
    "                    Plot=True, Title='Linear Calibration Curve', \n",
    "                  label_x='Measured Value', label_y='Predicted Value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "for i in range(0,len(sample_ids)):\n",
    "    target = concentration_data3.loc[\" \"+str(sample_ids[i]),'Li']\n",
    "    targets.append(target)\n",
    "targets = np.array(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cdf6ef87664d26801ca7e4c7d0a383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan' 'nan' 'nan' 'nan' 'nan' ' SCH' ' SCH' ' SCH' ' SCH' ' SCH'\n",
      " ' SCH+FGP' ' SCH+FGP' ' FGP+VQZ' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' SCH+FGP' ' SCH+FGP'\n",
      " ' FGP' ' FGP' ' SCH+FGP' ' SCH' ' SCH' ' SCH' ' SCH' ' SCH' ' SCH' ' SCH'\n",
      " ' SCH' ' SCH' ' SCH+FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' SCH+FGP' ' SCH+FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP' ' FGP'\n",
      " ' FGP' ' FGP' ' FGP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n",
      "C:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: scipy.where is deprecated and will be removed in SciPy 2.0.0, use numpy.where instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4731bd4fcab444d86f035fc2ba4023e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\nsubplots()\\nplot(intensities[:split0],'o',color='r')\\nplot(targets0[:split0],'o',color='r')\\nplot(intensities[split0:],'o',color='k')\\nplot(targets0[split0:],'o',color='k')\\nprint(targets[11])\\nprint(sample_ids[11])\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subplots()\n",
    "split0=39\n",
    "split1=82\n",
    "split2=124\n",
    "plot(targets0[:split0],intensities[:split0],'o',color='r')\n",
    "plot(targets0[split0:split1],intensities[split0:split1],'o',color='k')\n",
    "plot(targets0[split1:split2],intensities[split1:split2],'o',color='b')\n",
    "xlabel(\"Measured Concentration\")\n",
    "ylabel(\"Intensity of Line\")\n",
    "\n",
    "chemistry_labels=[]\n",
    "for i in range(0,len(sample_ids)):\n",
    "    chemistry_label = concentration_data3.loc[\" \"+str(sample_ids[i]),'Chemistry']\n",
    "    chemistry_labels.append(chemistry_label)\n",
    "\n",
    "chemistry_labels=np.array(chemistry_labels)\n",
    "print(chemistry_labels)\n",
    "index1 = where(chemistry_labels == ' SCH')[0]\n",
    "index2 = where(chemistry_labels == ' SCH+FGP')[0]\n",
    "index3 = where(chemistry_labels == ' FGP+VQZ')[0]\n",
    "index4 = where(chemistry_labels == ' FGP')[0]\n",
    "index5 = where(chemistry_labels == 'nan')[0]\n",
    "\n",
    "subplots()\n",
    "plot(targets0[index1],intensities[index1],'o',color='r',label='SCH')\n",
    "plot(targets0[index2],intensities[index2],'o',color='k',label = 'SCH+FGP')\n",
    "plot(targets0[index3],intensities[index3],'o',color='b',label='FGP+VQZ')\n",
    "plot(targets0[index4],intensities[index4],'o',color='y',label='FGP')\n",
    "plot(targets0[index5],intensities[index5],'o',color='g',label='nan')\n",
    "xlabel(\"Measured Concentration\")\n",
    "ylabel(\"Intensity of Line\")\n",
    "legend()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "subplots()\n",
    "plot(intensities[:split0],'o',color='r')\n",
    "plot(targets0[:split0],'o',color='r')\n",
    "plot(intensities[split0:],'o',color='k')\n",
    "plot(targets0[split0:],'o',color='k')\n",
    "print(targets[11])\n",
    "print(sample_ids[11])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Calibration model - multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcb037630f04c1aa06ca187004414ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41769967866757496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8a5e05fecb49ad93fa8967437ce18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36923110828298467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def linear_calibration_curve_multilines(list_of_experiments, targets, lines, ratio_of_maximum = 0.5, radius = 0.3, \n",
    "                    test_size=ts,random_seed=rs,\n",
    "                    Plot=True, Title='Linear Calibration Curve', \n",
    "                  label_x='Measured Value', label_y='Predicted Value'):\n",
    "\n",
    "    \n",
    "    intensities=[]\n",
    "    for i in range(len(lines)):\n",
    "        temp_intensities=[]\n",
    "        line=lines[i]\n",
    "        \n",
    "        for j in range(0,len(list_of_experiments)):\n",
    "            current_experiment = list_of_experiments[j]\n",
    "\n",
    "            #stich the wavelengths and spectrum (not the best way, but for now let us have it)\n",
    "            wavelengths = np.concatenate([w for w in current_experiment.mean_signal.wavelengths]) \n",
    "            spectrum = np.concatenate([s for s in current_experiment.mean_signal.spectrum ])\n",
    "\n",
    "            #get peak area\n",
    "            ritz = line.ritz\n",
    "            intensity = get_peak_area(ritz,ratio_of_maximum , wavelengths, spectrum, radius, False)\n",
    "            temp_intensities.append(intensity)\n",
    "\n",
    "        temp_intensities=np.array(temp_intensities)\n",
    "        intensities.append(np.array(temp_intensities))\n",
    "    intensities=np.array(intensities)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(np.transpose(intensities), targets.reshape(-1, 1), \n",
    "                                                            test_size=test_size, random_state=random_seed)\n",
    "    \n",
    "    UCC_model = linear_model.LinearRegression()\n",
    "    UCC_model.fit(X_train,y_train)\n",
    "    r2=UCC_model.score(X_test, y_test) \n",
    "    \n",
    "    if Plot:\n",
    "        subplots()\n",
    "\n",
    "        ###With baseline\n",
    "        #subplot(121)\n",
    "        title(\"Without Normalization - Mean Signal\")\n",
    "\n",
    "        ax = gca()\n",
    "        ax.text(0.6, 0.1,  '$r^2 =$' + \"%0.4f\" % r2,\n",
    "                        transform=ax.transAxes,fontsize=8, bbox={'boxstyle':'round', 'facecolor': 'wheat', 'alpha': 0.5, 'pad': 0.5})\n",
    "\n",
    "        print(r2)\n",
    "        predicted = UCC_model.predict(X_test)\n",
    "        predicted_train = UCC_model.predict(X_train)\n",
    "        plot(y_test,predicted,'o',color = 'r', markersize=4,label = 'Test Dataset')\n",
    "        plot(y_train,predicted_train,'o',color = 'grey', markersize=2, label = 'Train Dataset')\n",
    "\n",
    "        mm=max([max(targets),max(predicted)])\n",
    "        xyline =np.linspace(0,mm,5) \n",
    "        plot(xyline,xyline,'-',color = 'grey', lw=0.5)\n",
    "        xlabel(label_x)\n",
    "        ylabel(label_y)\n",
    "        legend()\n",
    "        \n",
    "    \n",
    "    return UCC_model, r2, intensities, targets\n",
    "\n",
    "\n",
    "line = lines[0]\n",
    "init = 0\n",
    "UCC_model, r2, intensities, targets0 = linear_calibration_curve_multilines(list_of_experiments[init:], targets[init:], \n",
    "                    [line_0], ratio_of_maximum = 0.5, radius = 0.3, \n",
    "                    test_size=ts,random_seed=rs,\n",
    "                    Plot=True, Title='Linear Calibration Curve', \n",
    "                  label_x='Measured Value', label_y='Predicted Value')\n",
    "\n",
    "UCC_model, r2, intensities, targets0 = linear_calibration_curve_multilines(list_of_experiments[init:], targets[init:], \n",
    "                    [line_0,line_1], ratio_of_maximum = 0.5, radius = 0.3, \n",
    "                    test_size=ts,random_seed=rs,\n",
    "                    Plot=True, Title='Linear Calibration Curve', \n",
    "                  label_x='Measured Value', label_y='Predicted Value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing density\n",
    "Using the H_alpha line from the Balmer series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density, x,y,p = sg.density_H_alpha()\n",
    "print(str(density) + \" cm^-3\")\n",
    "density= density*(10**2)**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.remove_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the plasma temperature\n",
    "Using the Saha-Boltzmann method and choosing the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the element for computing the relevant lines\n",
    "al = element('Li')\n",
    "\n",
    "Tp = 1.*T_ref\n",
    "\n",
    "#define the upper and lower limits to find the most relevant nlines\n",
    "#let us define to the\n",
    "n_spectrometer = 4\n",
    "ll = sg.wavelengths[n_spectrometer][0]\n",
    "ul = sg.wavelengths[n_spectrometer][-1]\n",
    "\n",
    "ion_energies = al.ion_energies\n",
    "\n",
    "#ion state 1\n",
    "nlines = 5\n",
    "l_num, lines = al.get_most_relevant_lines_ion_state(ion_state = 1, electron_temperature=Tp, n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "lines = lines.delete([])\n",
    "#ion state 2\n",
    "nlines = 2\n",
    "l_num2, lines2 = al.get_most_relevant_lines_ion_state(ion_state = 2, electron_temperature=Tp, n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "#compute the plasma temperature\n",
    "temperature, temp_95, r2, y_s, x_s = sg.saha_boltzmann_temperature_v2([lines,al,electron_density= density, \n",
    "                                                                      ratio_of_maximum = 0.5, radius = 0.1, Plot = True, Plotlines = True, use_max_intensity = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTE conditions\n",
    "Probing the Mcwrither criterium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_density = sg.LTE_MW_criterium(4.8,temperature)\n",
    "print(\"Minimum density in cm^-3: \" + str(\"%e\" %minimum_density))\n",
    "print(\"Computed density in cm^-3: \" + str(\"%e\" %(density*(10**-2)**3)))\n",
    "print(\"MW criterion - \" + str(density>(minimum_density*(10**2)**3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#construct a digital twin from the table data\n",
    "current = concentration_data.loc[sample_f]\n",
    "element_names = concentration_data.columns.values[1:]\n",
    "vals =  current.values[1:]\n",
    "sample_elements = []\n",
    "for i in range(0,len(vals)):\n",
    "    #sample_elements.append([element_names[i],vals[i]/vals[-1]])\n",
    "    sample_elements.append([element_names[i],vals[i]])\n",
    "\n",
    "\n",
    "sample = digital_twin(sample_elements)\n",
    "for i in range(0,len(sample.list_of_elements)):\n",
    "    sample.list_of_elements[i].ratio = sample.list_of_elements[i].ratio/(sample.list_of_elements[i].mass/ua)\n",
    "\n",
    "print(sample)\n",
    "\n",
    "for n_spectrometer in range(0,len(sg.wavelengths)):\n",
    "    ll = sg.wavelengths[n_spectrometer][0]\n",
    "    ul = sg.wavelengths[n_spectrometer][-1]\n",
    "\n",
    "    #ion state 1\n",
    "    nlines = 3\n",
    "    l_num, lines = al.get_most_relevant_lines_ion_state(ion_state = 1, electron_temperature=Tp, \n",
    "                                                        n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "    #line to normalize the intensity for direct\n",
    "    line_norm1=lines[1]\n",
    "    print(\"# Spectrometer 1 normalized to \" + str(line_norm1))\n",
    "\n",
    "    sg.compare_to_digital_sample(sample, spectrometer=n_spectrometer,max_ion_state=2, \n",
    "                                 electron_temperature = temperature,electron_density=density,\n",
    "                                 d_lambda=0.02, use_wavelengths=True,line_normalize=line_norm1,Plotline = True, resolution = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak detection and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spectrometer = 3\n",
    "\n",
    "ll = sg.wavelengths[n_spectrometer][0]\n",
    "ul = sg.wavelengths[n_spectrometer][-1]\n",
    "\n",
    "#ion state 1\n",
    "nlines = 3\n",
    "l_num, lines = al.get_most_relevant_lines_ion_state(ion_state = 1, electron_temperature=Tp, \n",
    "                                                        n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "#line to normalize the intensity for direct\n",
    "line_norm1=lines[1]\n",
    "print(\"# Spectrometer 1 normalized to \" + str(line_norm1))\n",
    "sg.wavelengths[n_spectrometer] = sg.wavelengths[n_spectrometer]+0.05\n",
    "\n",
    "sg.compare_and_peaks(sample, spectrometer=n_spectrometer,max_ion_state=2, \n",
    "                                 electron_temperature = temperature,electron_density=density,\n",
    "                                 d_lambda=0.02, use_wavelengths=True,line_normalize=line_norm1,Plotline = True, resolution = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tp = temperature\n",
    "sample1 = digital_twin([['Fe',1]])\n",
    "specs_0=[]\n",
    "for i in range(0,len(sg.wavelengths)):\n",
    "    wl,spec,label, n_ion, specs = sample1.spectrum_NIST(wl = sg.wavelengths[i], electron_temperature=Tp, electron_density = density, max_ion_state=2,resolution=10000)\n",
    "    specs_0.append(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "specs_0\n",
    "for i in range(0,len(specs_0)):\n",
    "    subplots()\n",
    "    subplot(311)\n",
    "    plot(sg.spectrum[i])\n",
    "    subplot(312)\n",
    "    plot(specs_0[i][0])\n",
    "    subplot(313)\n",
    "    conv = np.convolve(sg.spectrum[i],specs_0[i][0][::-1], mode='full')\n",
    "    #conv = np.convolve(specs_0[i][0],specs_0[i][0])\n",
    "    plot(np.arange(-len(sg.spectrum[i])+1,len(sg.spectrum[i])),log10(conv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sg.spectrum[0].shape)\n",
    "specs_0[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map of Lines in each spectrometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tp = temperature\n",
    "for i in range(0,len(sg.wavelengths)):\n",
    "    wl,spec,label, n_ion, specs = sample.spectrum_NIST(wl = sg.wavelengths[i], electron_temperature=Tp, electron_density = density, max_ion_state=3,d_lambda=0.01, Map=True)\n",
    "    ax = gca()\n",
    "    ax.set_title(\"Map of lines in Spectrometer \"+ str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the element for computing the relevant lines\n",
    "al = element('P')\n",
    "\n",
    "Tp = 1.*T_ref\n",
    "\n",
    "#define the upper and lower limits to find the most relevant nlines\n",
    "#let us define to the\n",
    "n_spectrometer = 6\n",
    "ll = sg.wavelengths[n_spectrometer][0]\n",
    "ul = sg.wavelengths[n_spectrometer][-1]\n",
    "\n",
    "#ion state 1\n",
    "nlines = 2\n",
    "l_num, lines = al.get_most_relevant_lines_ion_state(ion_state = 1, electron_temperature=Tp, n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "#ion state 2\n",
    "nlines = 2\n",
    "l_num2, lines2 = al.get_most_relevant_lines_ion_state(ion_state = 2, electron_temperature=Tp, n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "lines2 = delete(lines2, 0)\n",
    "#compute the plasma temperature\n",
    "temperature, temp_95, r2, y_s, x_s = sg.saha_boltzmann_temperature_v2([lines,lines2],al,electron_density= density, \n",
    "                                                                      ratio_of_maximum = 0.5, radius = 0.1, Plot = True, Plotlines = True, use_max_intensity = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = digital_twin([['Li',1],['Pb',1],['Zn',1],['Cu',1]])\n",
    "\n",
    "Tp = temperature\n",
    "for i in range(0,len(sg.wavelengths)):\n",
    "    wl,spec,label, n_ion, specs = sample.spectrum_NIST( lower_limit = 250, upper_limit = 800, max_ion_state=3,d_lambda=0.01, Map=True)\n",
    "    ax = gca()\n",
    "    ax.set_title(\"Map of lines in Spectrometer \"+ str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "i=2\n",
    "tck = interpolate.splrep(sg.wavelengths[i],sg.spectrum[i])\n",
    "xnew = np.linspace(sg.wavelengths[i][0], sg.wavelengths[i][-1], 5000)\n",
    "ynew = interpolate.splev(xnew, tck, der=0)\n",
    "subplots()\n",
    "plot(xnew,ynew/max(ynew))\n",
    "plot(sg.wavelengths[i],sg.spectrum[i]/max(sg.spectrum[i]), 'o', markersize=1,color='k')\n",
    "#plot(sg.wavelengths[i],specs_0[i][0]/(200))\n",
    "g=gradient(ynew,xnew)\n",
    "gg=gradient(g,xnew)\n",
    "plot(xnew,g/max(abs(g)),ls='-')\n",
    "plot(xnew,gg/max(abs(gg)),ls='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def tricubic(x):\n",
    "    y = np.zeros_like(x)\n",
    "    idx = (x >= -1) & (x <= 1)\n",
    "    y[idx] = np.power(1.0 - np.power(np.abs(x[idx]), 3), 3)\n",
    "    return y\n",
    "\n",
    "\n",
    "class Loess(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_array(array):\n",
    "        min_val = np.min(array)\n",
    "        max_val = np.max(array)\n",
    "        return (array - min_val) / (max_val - min_val), min_val, max_val\n",
    "\n",
    "    def __init__(self, xx, yy, degree=1):\n",
    "        self.n_xx, self.min_xx, self.max_xx = self.normalize_array(xx)\n",
    "        self.n_yy, self.min_yy, self.max_yy = self.normalize_array(yy)\n",
    "        self.degree = degree\n",
    "\n",
    "    @staticmethod\n",
    "    def get_min_range(distances, window):\n",
    "        min_idx = np.argmin(distances)\n",
    "        n = len(distances)\n",
    "        if min_idx == 0:\n",
    "            return np.arange(0, window)\n",
    "        if min_idx == n-1:\n",
    "            return np.arange(n - window, n)\n",
    "\n",
    "        min_range = [min_idx]\n",
    "        while len(min_range) < window:\n",
    "            i0 = min_range[0]\n",
    "            i1 = min_range[-1]\n",
    "            if i0 == 0:\n",
    "                min_range.append(i1 + 1)\n",
    "            elif i1 == n-1:\n",
    "                min_range.insert(0, i0 - 1)\n",
    "            elif distances[i0-1] < distances[i1+1]:\n",
    "                min_range.insert(0, i0 - 1)\n",
    "            else:\n",
    "                min_range.append(i1 + 1)\n",
    "        return np.array(min_range)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_weights(distances, min_range):\n",
    "        max_distance = np.max(distances[min_range])\n",
    "        weights = tricubic(distances[min_range] / max_distance)\n",
    "        return weights\n",
    "\n",
    "    def normalize_x(self, value):\n",
    "        return (value - self.min_xx) / (self.max_xx - self.min_xx)\n",
    "\n",
    "    def denormalize_y(self, value):\n",
    "        return value * (self.max_yy - self.min_yy) + self.min_yy\n",
    "\n",
    "    def estimate(self, x, window, use_matrix=False, degree=1):\n",
    "        n_x = self.normalize_x(x)\n",
    "        distances = np.abs(self.n_xx - n_x)\n",
    "        min_range = self.get_min_range(distances, window)\n",
    "        weights = self.get_weights(distances, min_range)\n",
    "\n",
    "        if use_matrix or degree > 1:\n",
    "            wm = np.multiply(np.eye(window), weights)\n",
    "            xm = np.ones((window, degree + 1))\n",
    "\n",
    "            xp = np.array([[math.pow(n_x, p)] for p in range(degree + 1)])\n",
    "            for i in range(1, degree + 1):\n",
    "                xm[:, i] = np.power(self.n_xx[min_range], i)\n",
    "\n",
    "            ym = self.n_yy[min_range]\n",
    "            xmt_wm = np.transpose(xm) @ wm\n",
    "            beta = np.linalg.pinv(xmt_wm @ xm) @ xmt_wm @ ym\n",
    "            y = (beta @ xp)[0]\n",
    "        else:\n",
    "            xx = self.n_xx[min_range]\n",
    "            yy = self.n_yy[min_range]\n",
    "            sum_weight = np.sum(weights)\n",
    "            sum_weight_x = np.dot(xx, weights)\n",
    "            sum_weight_y = np.dot(yy, weights)\n",
    "            sum_weight_x2 = np.dot(np.multiply(xx, xx), weights)\n",
    "            sum_weight_xy = np.dot(np.multiply(xx, yy), weights)\n",
    "\n",
    "            mean_x = sum_weight_x / sum_weight\n",
    "            mean_y = sum_weight_y / sum_weight\n",
    "\n",
    "            b = (sum_weight_xy - mean_x * mean_y * sum_weight) / \\\n",
    "                (sum_weight_x2 - mean_x * mean_x * sum_weight)\n",
    "            a = mean_y - b * mean_x\n",
    "            y = a + b * n_x\n",
    "        return self.denormalize_y(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wls=[]\n",
    "sps=[]\n",
    "for i in range(0, len(current_experiment.list_of_signals)):\n",
    "    wavelengths = np.concatenate([w for w in current_experiment.list_of_signals[i].wavelengths])\n",
    "    spectrum = np.concatenate([s for s in current_experiment.list_of_signals[i].spectrum ])\n",
    "    wls=np.concatenate([wls,wavelengths])\n",
    "    sps = np.concatenate([sps,spectrum])\n",
    "\n",
    "    \n",
    "xx = wls\n",
    "yy = sps\n",
    "\n",
    "loess = Loess(xx, yy)\n",
    "\n",
    "for x in xx:\n",
    "    y = loess.estimate(wls, window=5, use_matrix=False, degree=1)\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots()\n",
    "plot(xx,yy,'o',markersize=1)\n",
    "plot(xx,yy,'o',markersize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(sg.wavelengths)):\n",
    "    plot(sg.wavelengths[i],sg.spectrum[i],'-',color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "neigh = RadiusNeighborsRegressor(radius=.1)\n",
    "XX = xx.reshape(-1, 1)\n",
    "neigh.fit(XX, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xx,neigh.predict(XX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_wls.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.add_constant(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the element for computing the relevant lines\n",
    "al = element('Ca')\n",
    "\n",
    "Tp = 1.*T_ref\n",
    "\n",
    "#define the upper and lower limits to find the most relevant nlines\n",
    "#let us define to the\n",
    "n_spectrometer = 2\n",
    "ll = sg.wavelengths[n_spectrometer][0]\n",
    "ul = sg.wavelengths[n_spectrometer][-1]\n",
    "\n",
    "ion_energies = al.ion_energies\n",
    "\n",
    "#ion state 1\n",
    "nlines = 3\n",
    "l_num, lines = al.get_most_relevant_lines_ion_state(ion_state = 1, electron_temperature=Tp, n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "#ion state 2\n",
    "nlines = 2\n",
    "l_num2, lines2 = al.get_most_relevant_lines_ion_state(ion_state = 2, electron_temperature=Tp, n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "#compute the plasma temperature\n",
    "temperature, temp_95, r2, y_s, x_s = sg.saha_boltzmann_temperature_v2([lines,lines2],al,electron_density= density, \n",
    "                                                                      ratio_of_maximum = 0.5, radius = 0.1, Plot = True, Plotlines = True, use_max_intensity = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spectrometer = 2\n",
    "\n",
    "ll = sg.wavelengths[n_spectrometer][0]\n",
    "ul = sg.wavelengths[n_spectrometer][-1]\n",
    "\n",
    "#ion state 1\n",
    "nlines = 3\n",
    "l_num, lines = al.get_most_relevant_lines_ion_state(ion_state = 1, electron_temperature=Tp, \n",
    "                                                        n_lines = nlines,lower_limit = ll, upper_limit = ul)\n",
    "\n",
    "#line to normalize the intensity for direct\n",
    "line_norm1=lines[1]\n",
    "print(\"# Spectrometer 1 normalized to \" + str(line_norm1))\n",
    "sg.wavelengths[n_spectrometer] = sg.wavelengths[n_spectrometer]+0.05\n",
    "\n",
    "sg.compare_and_peaks(sample, spectrometer=n_spectrometer,max_ion_state=2, \n",
    "                                 electron_temperature = temperature,electron_density=density,\n",
    "                                 d_lambda=0.02, use_wavelengths=True,line_normalize=line_norm1,Plotline = True, resolution = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
